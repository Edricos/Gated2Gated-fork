{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 生成选通先验图"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c25ecae46ea31ab"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4014/4014 [03:35<00:00, 18.61it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def readlines(filename):\n",
    "    \"\"\"Read all the lines in a text file and return as a list\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "    return lines\n",
    "\n",
    "\n",
    "def read_img(img_path,\n",
    "             num_bits=10,\n",
    "             crop_height=420, crop_width=980, dataset='g2d'):\n",
    "    gated_imgs = []\n",
    "    normalizer = 2 ** num_bits - 1.\n",
    "\n",
    "    for gate_id in range(3):\n",
    "        path = img_path.format(gate_id)\n",
    "        assert os.path.exists(path), \"No such file : %s\" % path\n",
    "        img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "        img = img[((img.shape[0] - crop_height) // 2):((img.shape[0] + crop_height) // 2),\n",
    "              ((img.shape[1] - crop_width) // 2):((img.shape[1] + crop_width) // 2)]\n",
    "        img = img.copy()\n",
    "        img[img > 2 ** 10 - 1] = normalizer\n",
    "        img = np.float32(img / normalizer)\n",
    "        gated_imgs.append(np.expand_dims(img, axis=2))\n",
    "    img = np.concatenate(gated_imgs, axis=2)\n",
    "    return img\n",
    "\n",
    "\n",
    "#name = ['train','val','test']\n",
    "name = ['train']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data_path = r'C:\\Users\\edric\\PycharmProjects\\newG2D\\data\\real\\splits'\n",
    "fpath = os.path.join(data_path, \"real_{}_night.txt\")\n",
    "base_dir = r'C:\\Users\\edric\\PycharmProjects\\newG2D\\data\\real'\n",
    "ppath = r'C:\\Users\\edric\\PycharmProjects\\newG2D\\data\\real\\gated3_10bit_edric'\n",
    "\n",
    "for n in range(len(name)):\n",
    "    train_filenames = readlines(fpath.format(name[n]))\n",
    "    img_id = {}\n",
    "    for i in tqdm.tqdm(range(0, len(train_filenames))):\n",
    "        # print(\"{}/{}\".format(i, len(train_filenames)))\n",
    "        img_id[i] = train_filenames[i].split('\\n')\n",
    "        id = img_id[i][0]\n",
    "        gate_dir = os.path.join(base_dir, 'gated{}_10bit', '{}.png'.format(id))\n",
    "        in_img = read_img(gate_dir)\n",
    "        in_img = torch.tensor(in_img).unsqueeze(0).to(device=device) * 255\n",
    "        img_min, _ = torch.min(in_img, dim=3)\n",
    "        in_img[:, :, :, 0] = in_img[:, :, :, 0] - img_min\n",
    "        in_img[:, :, :, 1] = in_img[:, :, :, 1] - img_min\n",
    "        in_img[:, :, :, 2] = in_img[:, :, :, 2] - img_min\n",
    "        img_max, max_index = torch.max(in_img, dim=3)\n",
    "        s1 = img_max < 30\n",
    "        s2 = img_max > 220\n",
    "        max_index[s1] = -1\n",
    "        max_index[s2] = -1\n",
    "        max_index[max_index == 0] = 30\n",
    "        max_index[max_index == 1] = 100\n",
    "        max_index[max_index == 2] = 180\n",
    "        max_index[max_index == -1] = 0\n",
    "\n",
    "        cv2.imwrite(os.path.join(ppath, '{}.png'.format(id)), np.float32(max_index[0, :, :].cpu()))\n",
    "        \n",
    "        # plt.imshow(np.float32(max_index[0, :, :].cpu()), cmap='gray')  \n",
    "        # # plt.colorbar()\n",
    "        # plt.title(\"Gated Depth Prior)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "        # break\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T08:52:15.442666500Z",
     "start_time": "2024-01-18T08:48:37.865806900Z"
    }
   },
   "id": "58b455c9f4454d3a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建参数对象\n",
    "from src.optionsClass import TrainingOptions\n",
    "\n",
    "# Create an instance of TrainingOptions\n",
    "opt = TrainingOptions()\n",
    "\n",
    "# Set the values as per the shell commands\n",
    "opt.data_dir = \"./data\"\n",
    "opt.log_dir = \"./logs\"\n",
    "opt.coeff_fpath = \"chebychev\"\n",
    "opt.depth_flat_world_fpath = \"depth_flat_world\"\n",
    "opt.model_name = \"multinetwork\"\n",
    "opt.model_type = \"multinetwork\"\n",
    "opt.exp_name = \"multinetwork\"\n",
    "opt.models_to_load = [\"depth\", \"ambient\", \"encoder\", \"albedo\", \"pose\", \"pose_encoder\"]\n",
    "opt.load_weights_folder = \"./models/initialization\"\n",
    "opt.exp_num = 0\n",
    "opt.height = 512\n",
    "opt.width = 1024\n",
    "opt.num_bits = 10\n",
    "opt.scales = [0]\n",
    "opt.frame_ids = [0, -1, 1]\n",
    "opt.pose_model_type = \"separate_resnet\"\n",
    "opt.num_layers = 18\n",
    "opt.weights_init = \"pretrained\"\n",
    "opt.pose_model_input = \"pairs\"\n",
    "opt.min_depth = 0.1\n",
    "opt.max_depth = 100.0\n",
    "opt.dataset = \"gated\"\n",
    "opt.split = \"gated2gated\"\n",
    "opt.batch_size = 4\n",
    "opt.num_workers = 4\n",
    "opt.learning_rate = 2e-4\n",
    "opt.num_epochs = 20\n",
    "opt.scheduler_step_size = 15\n",
    "opt.disparity_smoothness = 0.001\n",
    "opt.log_frequency = 200\n",
    "opt.save_frequency = 1\n",
    "opt.cycle_weight = 0.05\n",
    "opt.depth_normalizer = 70.0\n",
    "opt.passive_weight = 0.01\n",
    "opt.cycle_loss = True\n",
    "opt.temporal_loss = True\n",
    "opt.sim_gated = True\n",
    "opt.v1_multiscale = True\n",
    "opt.infty_hole_mask = True\n",
    "opt.snr_mask = True\n",
    "opt.intensity_mask = True\n",
    "opt.passive_supervision = True\n",
    "\n",
    "import torch\n",
    "\n",
    "cudaIf = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cudaIf else \"cpu\")\n",
    "print(\"device=\", device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T10:58:19.940947100Z"
    }
   },
   "id": "ea630b62a929449"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PackNetSlim01 -- depth\n",
      "torch.Size([1, 3, 512, 1024])--x_in.shape\n",
      "torch.Size([1, 32, 512, 1024])--x.shape\n",
      "torch.Size([1, 32, 512, 1024])--x1.shape\n",
      "torch.Size([1, 32, 256, 512])--x1p.shape\n",
      "torch.Size([1, 64, 256, 512])--x2.shape\n",
      "torch.Size([1, 64, 128, 256])--x2p.shape\n",
      "torch.Size([1, 128, 128, 256])--x3.shape\n",
      "torch.Size([1, 128, 64, 128])--x3p.shape\n",
      "torch.Size([1, 256, 64, 128])--x4.shape\n",
      "torch.Size([1, 256, 32, 64])--x4p.shape\n",
      "torch.Size([1, 512, 32, 64])--x5.shape\n",
      "torch.Size([1, 512, 16, 32])--x5p.shape\n",
      "torch.Size([1, 512, 32, 64])--unpack5.shape\n",
      "torch.Size([1, 768, 32, 64])--concat5.shape\n",
      "torch.Size([1, 512, 32, 64])--iconv5.shape\n",
      "torch.Size([1, 256, 64, 128])--unpack4.shape\n",
      "torch.Size([1, 384, 64, 128])--concat4.shape\n",
      "torch.Size([1, 256, 64, 128])--iconv4.shape\n",
      "torch.Size([1, 1, 64, 128])--disp4.shape\n",
      "torch.Size([1, 1, 128, 256])--udisp4.shape\n",
      "torch.Size([1, 128, 128, 256])--unpack3.shape\n",
      "torch.Size([1, 193, 128, 256])--concat3.shape\n",
      "torch.Size([1, 128, 128, 256])--iconv3.shape\n",
      "torch.Size([1, 1, 128, 256])--disp3.shape\n",
      "torch.Size([1, 1, 256, 512])--udisp3.shape\n",
      "torch.Size([1, 64, 256, 512])--unpack2.shape\n",
      "torch.Size([1, 97, 256, 512])--concat2.shape\n",
      "torch.Size([1, 64, 256, 512])--iconv2.shape\n",
      "torch.Size([1, 1, 256, 512])--disp2.shape\n",
      "torch.Size([1, 1, 512, 1024])--udisp2.shape\n",
      "torch.Size([1, 32, 512, 1024])--unpack1.shape\n",
      "torch.Size([1, 65, 512, 1024])--concat1.shape\n",
      "torch.Size([1, 32, 512, 1024])--iconv1.shape\n",
      "torch.Size([1, 1, 512, 1024])--disp1.shape\n",
      "depth.parameters:  216\n"
     ]
    }
   ],
   "source": [
    "from src import networks\n",
    "\n",
    "# 创建一个torch张量\n",
    "x = torch.randn(1, 3, 512, 1024).to(device)\n",
    "\n",
    "parameters_to_train = []\n",
    "depth = networks.PackNetSlim01(\n",
    "    dropout=opt.dropout,\n",
    "    version=\"{}{}\".format(1, opt.feat_stack)\n",
    ")\n",
    "depth.to(device)\n",
    "if not opt.train_depth_normalizer:\n",
    "    parameters_to_train += list(depth.parameters())\n",
    "\n",
    "depth_out = depth(x)\n",
    "print('depth.parameters: ', len(list(depth.parameters())))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:00:48.290182200Z",
     "start_time": "2023-11-20T10:58:25.945109600Z"
    }
   },
   "id": "e1a204dd3ceea17b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "66a6367ca3ee748f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Cannot find folder ./models/initialization",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrainer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Trainer\n\u001B[1;32m----> 3\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[43mTrainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[1;32m~\\PycharmProjects\\Gated2Gated\\src\\trainer.py:164\u001B[0m, in \u001B[0;36mTrainer.__init__\u001B[1;34m(self, options)\u001B[0m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_lr_scheduler \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mStepLR(\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_optimizer,\n\u001B[0;32m    159\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt\u001B[38;5;241m.\u001B[39mscheduler_step_size,\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;241m0.1\u001B[39m\n\u001B[0;32m    161\u001B[0m )\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt\u001B[38;5;241m.\u001B[39mload_weights_folder \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 164\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexperiment number:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  Training model named:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt\u001B[38;5;241m.\u001B[39mexp_num, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt\u001B[38;5;241m.\u001B[39mmodel_name)\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModels and tensorboard events files are saved to:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt\u001B[38;5;241m.\u001B[39mlog_dir)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Gated2Gated\\src\\trainer.py:874\u001B[0m, in \u001B[0;36mTrainer.load_model\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    870\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Load model(s) from disk\u001B[39;00m\n\u001B[0;32m    871\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    872\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt\u001B[38;5;241m.\u001B[39mload_weights_folder \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexpanduser(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt\u001B[38;5;241m.\u001B[39mload_weights_folder)\n\u001B[1;32m--> 874\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt\u001B[38;5;241m.\u001B[39mload_weights_folder), \\\n\u001B[0;32m    875\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot find folder \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt\u001B[38;5;241m.\u001B[39mload_weights_folder)\n\u001B[0;32m    876\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloading model from folder \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt\u001B[38;5;241m.\u001B[39mload_weights_folder))\n\u001B[0;32m    878\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt\u001B[38;5;241m.\u001B[39mmodels_to_load:\n",
      "\u001B[1;31mAssertionError\u001B[0m: Cannot find folder ./models/initialization"
     ]
    }
   ],
   "source": [
    "from src.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(opt)\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:59:36.382955Z",
     "start_time": "2023-11-17T09:59:35.223341100Z"
    }
   },
   "id": "189612bc7c4e3816"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
